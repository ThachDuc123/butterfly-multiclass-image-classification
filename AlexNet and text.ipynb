{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-09T14:59:29.742856Z",
     "iopub.status.busy": "2025-03-09T14:59:29.742534Z",
     "iopub.status.idle": "2025-03-09T14:59:29.748104Z",
     "shell.execute_reply": "2025-03-09T14:59:29.747122Z",
     "shell.execute_reply.started": "2025-03-09T14:59:29.742823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T14:59:29.751263Z",
     "iopub.status.busy": "2025-03-09T14:59:29.751020Z",
     "iopub.status.idle": "2025-03-09T14:59:29.764003Z",
     "shell.execute_reply": "2025-03-09T14:59:29.763148Z",
     "shell.execute_reply.started": "2025-03-09T14:59:29.751235Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng thiết bị: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Sử dụng thiết bị: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T14:59:29.765275Z",
     "iopub.status.busy": "2025-03-09T14:59:29.764955Z",
     "iopub.status.idle": "2025-03-09T14:59:29.789309Z",
     "shell.execute_reply": "2025-03-09T14:59:29.788558Z",
     "shell.execute_reply.started": "2025-03-09T14:59:29.765255Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>SOUTHERN DOGFACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>ADONIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>BROWN SIPROETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>MONARCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>GREEN CELLED CATTLEHEART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Image_6.jpg</td>\n",
       "      <td>CAIRNS BIRDWING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Image_7.jpg</td>\n",
       "      <td>GREEN CELLED CATTLEHEART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Image_8.jpg</td>\n",
       "      <td>EASTERN DAPPLE WHITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Image_9.jpg</td>\n",
       "      <td>BROWN SIPROETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Image_10.jpg</td>\n",
       "      <td>RED POSTMAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename                     label\n",
       "0   Image_1.jpg          SOUTHERN DOGFACE\n",
       "1   Image_2.jpg                    ADONIS\n",
       "2   Image_3.jpg            BROWN SIPROETA\n",
       "3   Image_4.jpg                   MONARCH\n",
       "4   Image_5.jpg  GREEN CELLED CATTLEHEART\n",
       "5   Image_6.jpg           CAIRNS BIRDWING\n",
       "6   Image_7.jpg  GREEN CELLED CATTLEHEART\n",
       "7   Image_8.jpg      EASTERN DAPPLE WHITE\n",
       "8   Image_9.jpg            BROWN SIPROETA\n",
       "9  Image_10.jpg               RED POSTMAN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/ai-1810-dpl-302-m-butterfly-image-classification/Training_set.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T14:59:29.791206Z",
     "iopub.status.busy": "2025-03-09T14:59:29.790784Z",
     "iopub.status.idle": "2025-03-09T14:59:29.796326Z",
     "shell.execute_reply": "2025-03-09T14:59:29.795452Z",
     "shell.execute_reply.started": "2025-03-09T14:59:29.791154Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T14:59:29.797909Z",
     "iopub.status.busy": "2025-03-09T14:59:29.797612Z",
     "iopub.status.idle": "2025-03-09T14:59:29.809135Z",
     "shell.execute_reply": "2025-03-09T14:59:29.807979Z",
     "shell.execute_reply.started": "2025-03-09T14:59:29.797888Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lớp bướm khác nhau: 75\n"
     ]
    }
   ],
   "source": [
    "if 'label' in df.columns:\n",
    "    num_classes = df['label'].nunique()\n",
    "    label_column = 'label'\n",
    "    print(f\"Số lớp bướm khác nhau: {num_classes}\")\n",
    "else:\n",
    "    possible_label_columns = ['category', 'class', 'type', 'species']\n",
    "    for col in possible_label_columns:\n",
    "        if col in df.columns:\n",
    "            label_column = col\n",
    "            num_classes = df[col].nunique()\n",
    "            print(f\"Tìm thấy cột nhãn: {label_column}\")\n",
    "            print(f\"Số lớp bướm khác nhau: {num_classes}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Không tìm thấy cột nhãn rõ ràng. Giả định cột thứ hai là nhãn.\")\n",
    "        label_column = df.columns[1]\n",
    "        num_classes = df[label_column].nunique()\n",
    "        print(f\"Sử dụng cột {label_column} làm nhãn với {num_classes} lớp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T14:59:29.831526Z",
     "iopub.status.busy": "2025-03-09T14:59:29.831327Z",
     "iopub.status.idle": "2025-03-09T14:59:29.852402Z",
     "shell.execute_reply": "2025-03-09T14:59:29.851498Z",
     "shell.execute_reply.started": "2025-03-09T14:59:29.831505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng ảnh huấn luyện: 4000\n",
      "Số lượng ảnh validation: 1000\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"/kaggle/input/ai-1810-dpl-302-m-butterfly-image-classification/train/train\"\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[label_column], random_state=42)\n",
    "print(f\"Số lượng ảnh huấn luyện: {len(train_df)}\")\n",
    "print(f\"Số lượng ảnh validation: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T14:59:29.900443Z",
     "iopub.status.busy": "2025-03-09T14:59:29.900230Z",
     "iopub.status.idle": "2025-03-09T14:59:29.918043Z",
     "shell.execute_reply": "2025-03-09T14:59:29.917069Z",
     "shell.execute_reply.started": "2025-03-09T14:59:29.900425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset và DataLoader đã được tạo thành công!\n"
     ]
    }
   ],
   "source": [
    "class ButterflyDataset(Dataset):\n",
    "    def __init__(self, data_frame, img_dir, transform=None, is_test=False, label_col='label'):\n",
    "        self.data_frame = data_frame\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.label_col = label_col\n",
    "        \n",
    "        if not is_test:\n",
    "            self.classes = sorted(data_frame[label_col].unique())\n",
    "            self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            for ext in ['.jpg', '.jpeg', '.png']:\n",
    "                if os.path.exists(img_path + ext):\n",
    "                    img_path = img_path + ext\n",
    "                    break\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc ảnh {img_path}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), color='gray')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if not self.is_test:\n",
    "            label_name = self.data_frame.iloc[idx, 1] if self.label_col=='label' else self.data_frame.iloc[idx][self.label_col]\n",
    "            label = self.class_to_idx[label_name]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, img_name\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3))\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "try:\n",
    "    train_dataset = ButterflyDataset(\n",
    "        data_frame=train_df,\n",
    "        img_dir=image_dir,\n",
    "        transform=train_transforms,\n",
    "        label_col=label_column\n",
    "    )\n",
    "    val_dataset = ButterflyDataset(\n",
    "        data_frame=val_df,\n",
    "        img_dir=image_dir,\n",
    "        transform=val_transforms,\n",
    "        label_col=label_column\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "    \n",
    "    print(\"Dataset và DataLoader đã được tạo thành công!\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tạo dataset: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T14:59:29.919840Z",
     "iopub.status.busy": "2025-03-09T14:59:29.919541Z",
     "iopub.status.idle": "2025-03-09T14:59:31.084323Z",
     "shell.execute_reply": "2025-03-09T14:59:31.083568Z",
     "shell.execute_reply.started": "2025-03-09T14:59:29.919808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Hàm tạo mô hình sử dụng AlexNet\n",
    "def create_model(num_classes):\n",
    "    model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)  # Dùng pretrained weights\n",
    "    \n",
    "    # Freeze toàn bộ các layers ngoại trừ classifier\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Thay đổi fully connected cuối cùng\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(9216, 4096),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 1024),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(1024, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = create_model(num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T14:59:31.086612Z",
     "iopub.status.busy": "2025-03-09T14:59:31.086380Z",
     "iopub.status.idle": "2025-03-09T14:59:31.090096Z",
     "shell.execute_reply": "2025-03-09T14:59:31.089295Z",
     "shell.execute_reply.started": "2025-03-09T14:59:31.086593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T14:59:31.091868Z",
     "iopub.status.busy": "2025-03-09T14:59:31.091597Z",
     "iopub.status.idle": "2025-03-09T14:59:31.102190Z",
     "shell.execute_reply": "2025-03-09T14:59:31.101387Z",
     "shell.execute_reply.started": "2025-03-09T14:59:31.091840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Định nghĩa hàm mất mát với label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Sử dụng optimizer Adam với weight decay\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Scheduler Cosine Annealing\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T15:00:00.912220Z",
     "iopub.status.busy": "2025-03-09T15:00:00.911815Z",
     "iopub.status.idle": "2025-03-09T15:00:00.916556Z",
     "shell.execute_reply": "2025-03-09T15:00:00.915814Z",
     "shell.execute_reply.started": "2025-03-09T15:00:00.912149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '/kaggle/working/'\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T15:00:02.142872Z",
     "iopub.status.busy": "2025-03-09T15:00:02.142580Z",
     "iopub.status.idle": "2025-03-09T15:00:02.152264Z",
     "shell.execute_reply": "2025-03-09T15:00:02.151264Z",
     "shell.execute_reply.started": "2025-03-09T15:00:02.142850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "def train_model(model, train_loader, val_loader, epoch, criterion, optimizer, scheduler=None):\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epochs in range(epoch):\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0, 0, 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f'Epoch {epochs+1}/{epoch} [Train]'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "        \n",
    "        history['train_losses'].append(train_loss / len(train_loader.dataset))\n",
    "        history['train_accs'].append(train_correct / train_total)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f'Epoch {epochs+1}/{epoch} [Val]'):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        history['val_losses'].append(val_loss / len(val_loader.dataset))\n",
    "        history['val_accs'].append(val_correct / val_total)\n",
    "\n",
    "        print(f'\\nEpoch {epochs+1}/{epoch}: Train Loss: {history[\"train_losses\"][-1]:.4f}, Train Acc: {history[\"train_accs\"][-1]:.4f}, Val Loss: {history[\"val_losses\"][-1]:.4f}, Val Acc: {history[\"val_accs\"][-1]:.4f}')\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            \n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), os.path.join(OUTPUT_PATH, 'alexnet_model.pth'))\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T15:00:04.282096Z",
     "iopub.status.busy": "2025-03-09T15:00:04.281790Z",
     "iopub.status.idle": "2025-03-09T15:00:04.286081Z",
     "shell.execute_reply": "2025-03-09T15:00:04.285122Z",
     "shell.execute_reply.started": "2025-03-09T15:00:04.282072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = {'train_losses': [], 'train_accs': [], 'val_losses': [], 'val_accs': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T15:00:06.144909Z",
     "iopub.status.busy": "2025-03-09T15:00:06.144597Z",
     "iopub.status.idle": "2025-03-09T15:03:43.254409Z",
     "shell.execute_reply": "2025-03-09T15:03:43.253279Z",
     "shell.execute_reply.started": "2025-03-09T15:00:06.144885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.19it/s]\n",
      "Epoch 1/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20: Train Loss: 2.3375, Train Acc: 0.5200, Val Loss: 1.7419, Val Acc: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.01it/s]\n",
      "Epoch 2/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/20: Train Loss: 2.0170, Train Acc: 0.6192, Val Loss: 1.5917, Val Acc: 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.29it/s]\n",
      "Epoch 3/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20: Train Loss: 1.8977, Train Acc: 0.6562, Val Loss: 1.5194, Val Acc: 0.7870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.16it/s]\n",
      "Epoch 4/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/20: Train Loss: 1.7920, Train Acc: 0.7020, Val Loss: 1.4999, Val Acc: 0.8120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Train]: 100%|██████████| 63/63 [00:09<00:00,  6.85it/s]\n",
      "Epoch 5/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/20: Train Loss: 1.7273, Train Acc: 0.7200, Val Loss: 1.4251, Val Acc: 0.8290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.23it/s]\n",
      "Epoch 6/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/20: Train Loss: 1.6751, Train Acc: 0.7362, Val Loss: 1.4302, Val Acc: 0.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.21it/s]\n",
      "Epoch 7/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/20: Train Loss: 1.6035, Train Acc: 0.7658, Val Loss: 1.3510, Val Acc: 0.8560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Train]: 100%|██████████| 63/63 [00:09<00:00,  6.88it/s]\n",
      "Epoch 8/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/20: Train Loss: 1.5699, Train Acc: 0.7755, Val Loss: 1.3461, Val Acc: 0.8620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.37it/s]\n",
      "Epoch 9/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/20: Train Loss: 1.5315, Train Acc: 0.7890, Val Loss: 1.3275, Val Acc: 0.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.39it/s]\n",
      "Epoch 10/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/20: Train Loss: 1.4832, Train Acc: 0.8043, Val Loss: 1.3208, Val Acc: 0.8660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Train]: 100%|██████████| 63/63 [00:09<00:00,  6.85it/s]\n",
      "Epoch 11/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/20: Train Loss: 1.4486, Train Acc: 0.8203, Val Loss: 1.3042, Val Acc: 0.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.26it/s]\n",
      "Epoch 12/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/20: Train Loss: 1.4245, Train Acc: 0.8267, Val Loss: 1.2810, Val Acc: 0.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.38it/s]\n",
      "Epoch 13/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/20: Train Loss: 1.3909, Train Acc: 0.8395, Val Loss: 1.2711, Val Acc: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Train]: 100%|██████████| 63/63 [00:09<00:00,  6.88it/s]\n",
      "Epoch 14/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/20: Train Loss: 1.3545, Train Acc: 0.8545, Val Loss: 1.2612, Val Acc: 0.8870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.38it/s]\n",
      "Epoch 15/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/20: Train Loss: 1.3521, Train Acc: 0.8518, Val Loss: 1.2690, Val Acc: 0.8770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.46it/s]\n",
      "Epoch 16/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/20: Train Loss: 1.3335, Train Acc: 0.8602, Val Loss: 1.2573, Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.03it/s]\n",
      "Epoch 17/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/20: Train Loss: 1.3336, Train Acc: 0.8582, Val Loss: 1.2518, Val Acc: 0.8890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.36it/s]\n",
      "Epoch 18/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/20: Train Loss: 1.3191, Train Acc: 0.8630, Val Loss: 1.2488, Val Acc: 0.8870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.40it/s]\n",
      "Epoch 19/20 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/20: Train Loss: 1.3005, Train Acc: 0.8695, Val Loss: 1.2480, Val Acc: 0.8880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Train]: 100%|██████████| 63/63 [00:08<00:00,  7.12it/s]\n",
      "Epoch 20/20 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/20: Train Loss: 1.3209, Train Acc: 0.8562, Val Loss: 1.2480, Val Acc: 0.8880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, train_loader, val_loader, 20, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T15:14:01.171037Z",
     "iopub.status.busy": "2025-03-09T15:14:01.170697Z",
     "iopub.status.idle": "2025-03-09T15:14:06.357142Z",
     "shell.execute_reply": "2025-03-09T15:14:06.356284Z",
     "shell.execute_reply.started": "2025-03-09T15:14:01.171005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-1734976b1700>:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, 'alexnet_model.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tìm thấy 1499 ảnh trong thư mục test và các thư mục con.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang dự đoán...: 100%|██████████| 24/24 [00:03<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo file submission với 1499 dự đoán hợp lệ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Test_dir = \"/kaggle/input/ai-1810-dpl-302-m-butterfly-image-classification/test/test\"\n",
    "def process_test_folder(test_dir, transform):\n",
    "    if not os.path.exists(test_dir):\n",
    "        print(f\"Không tìm thấy thư mục test: {test_dir}\")\n",
    "        return None\n",
    "    \n",
    "    # Quét tất cả thư mục con và thu thập file ảnh hợp lệ\n",
    "    test_files = []\n",
    "    val_extensions = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "    \n",
    "    for root, dirs, files in os.walk(test_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(val_extensions):\n",
    "                # Lấy đường dẫn tương đối so với test_dir\n",
    "                rel_path = os.path.relpath(os.path.join(root, file), test_dir)\n",
    "                test_files.append(rel_path)\n",
    "    \n",
    "    if not test_files:\n",
    "        print(\"Không tìm thấy file ảnh hợp lệ trong thư mục test!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Đã tìm thấy {len(test_files)} ảnh trong thư mục test và các thư mục con.\")\n",
    "    test_df = pd.DataFrame({'image': test_files})\n",
    "\n",
    "    class TestDataset(Dataset):\n",
    "        def __init__(self, file_list, dir_path, transform=None):\n",
    "            self.file_list = file_list\n",
    "            self.dir_path = dir_path\n",
    "            self.transform = transform\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.file_list)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            img_name = self.file_list[idx]\n",
    "            img_path = os.path.join(self.dir_path, img_name)\n",
    "            \n",
    "            # Kiểm tra và xử lý lỗi đường dẫn\n",
    "            if not os.path.isfile(img_path):\n",
    "                print(f\"Lỗi đường dẫn: {img_path} không phải là file!\")\n",
    "                return torch.zeros((3, 224, 224)), \"invalid\"\n",
    "            \n",
    "            try:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                return image, img_name\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi xử lý ảnh {img_path}: {str(e)}\")\n",
    "                return torch.zeros((3, 224, 224)), \"invalid\"\n",
    "\n",
    "    test_dataset = TestDataset(test_df['image'].values, test_dir, transform)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        collate_fn=lambda x: (torch.stack([item[0] for item in x]), [item[1] for item in x])\n",
    "    )\n",
    "    \n",
    "    return test_loader\n",
    "\n",
    "# CẬP NHẬT HÀM DỰ ĐOÁN\n",
    "def predict_and_submit(model, test_loader, class_mapping, output_path):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    filenames = []\n",
    "    idx_to_class = {v: k for k, v in class_mapping.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, batch_names in tqdm(test_loader, desc=\"Đang dự đoán...\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            predictions.extend([idx_to_class[idx.item()] for idx in predicted])\n",
    "            filenames.extend(batch_names)\n",
    "    \n",
    "    # Lọc các dự đoán không hợp lệ\n",
    "    val_data = [(f, p) for f, p in zip(filenames, predictions) if f != \"invalid\"]\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'Id': [f for f, p in val_data],\n",
    "        'Category': [p for f, p in val_data]\n",
    "    })\n",
    "    \n",
    "    submission_path = os.path.join(output_path, 'submission.csv')\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"Đã tạo file submission với {len(submission_df)} dự đoán hợp lệ.\")\n",
    "if os.path.exists(Test_dir):\n",
    "    best_model = create_model(num_classes)\n",
    "    best_model.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, 'alexnet_model.pth')))\n",
    "    best_model = best_model.to(device)\n",
    "    \n",
    "    test_loader = process_test_folder(Test_dir, val_transforms)\n",
    "    \n",
    "    if test_loader:\n",
    "        predict_and_submit(best_model, test_loader, train_dataset.class_to_idx, OUTPUT_PATH)\n",
    "    else:\n",
    "        print(\"Không thể tạo test loader do thiếu dữ liệu.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11168888,
     "sourceId": 93855,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
